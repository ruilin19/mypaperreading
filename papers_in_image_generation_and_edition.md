# Papers in Image Generation and Edition
## Diffusion models
1. Imagic: Text-Based Real Image Editing with Diffusion Models
     - [project](https://imagic-editing.github.io/)
     - [paper](https://arxiv.org/abs/2210.09276)
2. UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation Model on a Single Image
     - [paper](https://arxiv.org/abs/2210.09477)
3. SINE: SINgle Image Editing with Text-to-Image Diffusion Models
     - [project](https://zhang-zx.github.io/SINE/)
     - [paper](https://arxiv.org/abs/2212.04489)
     - [github](https://github.com/zhang-zx/SINE)
4. Prompt-to-Prompt Image Editing with Cross Attention Control & Null-text Inversion for Editing Real Images using Guided Diffusion Models
     - [project](https://prompt-to-prompt.github.io/) & [project](https://null-text-inversion.github.io/)
     - [paper](https://arxiv.org/abs/2208.01626) & [paper](https://arxiv.org/abs/2211.09794)
     - [github](https://github.com/google/prompt-to-prompt)
5. Zero-shot Image-to-Image Translation
     - [project](https://pix2pixzero.github.io/)
     - [paper](https://arxiv.org/abs/2302.03027)
     - [github](https://github.com/pix2pixzero/pix2pix-zero)
     - [huggen face](https://huggingface.co/docs/diffusers/v0.17.1/en/api/pipelines/pix2pix_zero)
6. DiffEdit: Diffusion-based semantic image editing with mask guidance
     - [paper](https://arxiv.org/abs/2210.11427)
     - [huggen face](https://huggingface.co/docs/diffusers/v0.17.1/en/api/pipelines/diffedit)
7. InstructPix2Pix: Learning to Follow Image Editing Instructions
     - [project](https://www.timothybrooks.com/instruct-pix2pix/)
     - [paper](https://arxiv.org/abs/2211.09800)
     - [github](https://github.com/timothybrooks/instruct-pix2pix)
     - [huggen face](https://huggingface.co/docs/diffusers/v0.17.1/en/api/pipelines/pix2pix)
     - [Youtube](https://www.youtube.com/watch?v=zcG7tG3xS3s)
     - [mini dataset on huggen face](https://huggingface.co/datasets/fusing/instructpix2pix-1000-samples)
8. RePaint: Inpainting using Denoising Diffusion Probabilistic Models
     - [website](https://deepai.org/publication/repaint-inpainting-using-denoising-diffusion-probabilistic-models)
     - [paper](https://arxiv.org/abs/2201.09865)
     - [github](https://github.com/andreas128/RePaint)
     - [huggen face](https://huggingface.co/docs/diffusers/api/pipelines/repaint)
9. Versatile Diffusion: Text, Images and Variations All in One Diffusion Model
     - [paper](https://arxiv.org/abs/2211.08332)
     - [github](https://github.com/SHI-Labs/Versatile-Diffusion)
     - [huggen face](https://huggingface.co/docs/diffusers/v0.17.1/en/api/pipelines/versatile_diffusion)
10. Blended Diffusion: Text-driven Editing of Natural Images
     - [project](https://omriavrahami.com/blended-diffusion-page/)
     - [paper](https://arxiv.org/abs/2111.14818)
     - [github](https://github.com/omriav/blended-diffusion)
11. SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations
     - [project](https://sde-image-editing.github.io/)
     - [paper](https://arxiv.org/abs/2108.01073)
     - [github](https://github.com/ermongroup/SDEdit)
12. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation
     - [paper](https://arxiv.org/abs/2110.02711)
     - [github](https://github.com/gwang-kim/DiffusionCLIP)
13. An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion
     - [project](https://textual-inversion.github.io/)
     - [paper](https://arxiv.org/abs/2208.01618)
     - [github](https://github.com/rinongal/textual_inversion)
14. DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation
     - [project](https://dreambooth.github.io/)
     - [paper](https://arxiv.org/abs/2208.12242)
     - [github(using the stable diffusion)](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion)
15. DALL·Es
     - [DALL·E](https://arxiv.org/abs/2102.12092)
     - [DALL·E 2](https://arxiv.org/abs/2204.06125)
16. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
     - [paper](https://arxiv.org/abs/2112.10741)
     - [github](https://github.com/openai/glide-text2im)
17. High-Resolution Image Synthesis with Latent Diffusion Models
     - [project](https://ommer-lab.com/research/latent-diffusion-models/)
     - [paper](https://arxiv.org/abs/2112.10752)
     - [github](https://github.com/CompVis/stable-diffusion)
## GAN models
1. DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation
     - [paper](https://arxiv.org/abs/2303.06285)
     - [github](https://github.com/Yueming6568/DeltaEdit)
2. StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery
     - [paper](https://arxiv.org/abs/2103.17249)
     - [github](https://github.com/orpatashnik/StyleCLIP)
## Evaluation
1. (FID)GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium
     - [tensorflow code](https://github.com/bioinf-jku/TTUR)
     - [pytorch code](https://github.com/mseitzer/pytorch-fid)
2. (IS)Inception Score
     - [pytorch code](https://github.com/sbarratt/inception-score-pytorch)
3. Huggen Face Tools
     - [doc](https://huggingface.co/docs/diffusers/v0.17.1/en/conceptual/evaluation)